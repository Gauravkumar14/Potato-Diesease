{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78293569",
   "metadata": {},
   "source": [
    "1st actually is to download the data set into tf dataset TF data input pipeline and then we will do some data cleaning and we will make our data set ready for model traing. So that's purpose of this video.\n",
    "\n",
    "###### What is a TF dataset?*\n",
    "TensorFlow Datasets* is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks, such as Jax. All datasets are exposed as tf. data. Datasets , enabling easy-to-use and high-performance input pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d235ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS=3 # 3 -  RGB \n",
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aed126",
   "metadata": {},
   "source": [
    "tf.keras.utils.image_dataset_from_directory( directory, labels='inferred', label_mode='int', class_names=None,\n",
    "\n",
    "    color_mode='rgb', batch_size=32, image_size=(256, 256), shuffle=True, seed=None, validation_split=None, subset=None,  \n",
    "    \n",
    "    interpolation='bilinear', follow_links=False, crop_to_aspect_ratio=False,\n",
    "    \n",
    "    **kwargs\n",
    ")\n",
    "##### Explanation\n",
    "=> directory == \"PlantVillage\"\n",
    "\n",
    "=> {shuffle = True } => Shuffle equal to true so that is will just randomly shuffle the images and load them \n",
    "\n",
    "=> Image size : 256X256 \n",
    "              =} dimensions = 256X256\n",
    "              =} width = 256 \n",
    "              =} hight = 256\n",
    "              \n",
    "=> batch_size = 32 (batch_size is the 32 is the like standard batch_size  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PlantVillage\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58cf7aa",
   "metadata": {},
   "source": [
    "Classes belonging to three classes by \"PlantVillage\"\n",
    "\n",
    "Basically folder names are your class names\n",
    "\n",
    "these are 3 folders : ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n",
    "\n",
    "'Potato___Early_blight'  =  1000 images\n",
    "\n",
    ", 'Potato___Late_blight' =  1000 images \n",
    "\n",
    ", 'Potato___healthy'     =  152 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee294ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bdc44",
   "metadata": {},
   "source": [
    "###### Do you have any clue why is it showing 68 ?\n",
    "Because every element in the data set is acutually a batch of 32 images\n",
    "###### 68X32 = > 2176  \n",
    "the last batch is not perfect so it is showing little more than 2152\n",
    "\n",
    "###### So lets just explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in dataset.take(1):\n",
    "    print(image_batch[0].shape)\n",
    "# shape of the 1st image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets say i want to visualize this image\n",
    "# :  Its a matlpotilb plot : plt.imshow() : imshow it expects 3d array \n",
    "# 1_batch = 32 images ,\n",
    "plt.figure(figsize=(10,10)) # area blw the all the leaves\n",
    "for image_batch, label_batch in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        # Subplot (3,4) like matrix\n",
    "        ax = plt.subplot(3,4,i+1)\n",
    "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[label_batch[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154ec26",
   "metadata": {},
   "source": [
    "###### Now we are going to splits our date set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74398aa",
   "metadata": {},
   "source": [
    "#80% ==> training\n",
    "\n",
    "#20% ==> 10% validation,10% test\n",
    "\n",
    "Validaton set will be used during the training process on when you run each epoch afer each we do validation on this 10%. At the end of every epoch we use this validation data set to do the validation.\n",
    "\n",
    "=> Once we are done througth 20 epochs, Onces we have final model then we use this 10% test dateset to measure the accuracy of our model\n",
    "\n",
    "=> Before we deploy our model into the wild , we want to use this 10% test data set to test the performances of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd639ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "len(dataset)*train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds =dataset\n",
    "train_ds = dataset.take(54)\n",
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0430dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dataset.skip(54)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.1\n",
    "len(dataset)*val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = test_ds.take(6)\n",
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a88290",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.skip(6)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd864e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now what we done about split date. { now we are showing in python function call it}\n",
    "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
    "    assert (train_split + test_split + val_split) == 1\n",
    "    \n",
    "    ds_size = len(ds)\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "        # Seed is just for predictability seed it can be any number .\n",
    "    \n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    val_size = int(val_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)    \n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d540a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab1ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e295449",
   "metadata": {},
   "source": [
    "# Cache, Shuffle, and Prefetch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6617093",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563f975",
   "metadata": {},
   "source": [
    "###### Now my these data sets are kind of optimizes for training preformance . So then training will run fast "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6009d29",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "\n",
    "### Creating a Layer for Resizing and Normalization\n",
    "\n",
    "Before we feed our images to network, we should be resizing it to the desired size. Moreover, to improve model performance, we should normalize the image pixel value (keeping them in range 0 and 1 by dividing by 256). This should happen while training as well as inference. Hence we can add that as a layer in our Sequential Model.\n",
    "\n",
    "You might be thinking why do we need to resize (256,256) image to again (256,256). You are right we don't need to but this will be useful when we are done with the training and start using the model for predictions. At that time somone can supply an image that is not (256,256) and this layer will resize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcfbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing --> rescaling \n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63d31b",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "Data Augmentation is needed when we have less data, this boosts the accuracy of our model by augmenting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6139a9",
   "metadata": {},
   "source": [
    "### Applying Data Augmentation to Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a2ed7",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "We use a CNN coupled with a Softmax activation in the output layer. We also add the initial layers for resizing, normalization and Data Augmentation.\n",
    "\n",
    "#### We are going to use convolutional neural network (CNN) here. CNN is popular for image classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3339c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    layers.Conv2D(filters=32, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef51bc",
   "metadata": {},
   "source": [
    "## Part 1 :\n",
    "#### (A) Convolution Layer\n",
    "\n",
    "tf.keras.layers.Conv2D( filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1),\n",
    "    groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "    kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "#### filters :\n",
    "###### No of filters  --> One filter could be to detect eye ,One filter could be to detect noise ..like that --> 32 layers  i am taking trial and error in project.\n",
    "###### Next layer --> 64 layer --> that i am taking trial and error.                        \n",
    "\n",
    "#####  kernel_size : \n",
    "###### Basically size of the filters --> 3 by 3 -->  (3 , 3)\n",
    "\n",
    "##### Then coming to Activation layer :  \n",
    "###### the popular activation layer for hidden layer is always 'relu' because its very fast to compute \n",
    "\n",
    "###### Input_shape -->\n",
    "###### its 255 by 255 --> (Image_size , Image_size) --> (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS) \n",
    "#### (B) Pooling Layer : \n",
    "\n",
    "###### Here i want max pooling layer of size 2d .\n",
    "###### Max pooling 2 by 2 filter with stride = 2\n",
    "###### Before i tired maybe i need to stack few max pooling and convert 2d layers  --Total -( 6 )\n",
    "\n",
    "### Part 2\n",
    "##### 1.  layers.Flatten --> Flattren layer \n",
    "##### 2.Dense layer \n",
    "##### 3. Last layer will have three neurons with soft max activation functon\n",
    "###### Soft max activation function is it will normalize the probability os your classes \n",
    "\n",
    "\n",
    "### Last :  Model_ Input\n",
    "##### model.build(input_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c756ee0",
   "metadata": {},
   "source": [
    "##### These paremetes are weights -->( total params : 183 , 747 ) that we need to train thats y  its tells trianable parameter . \n",
    "\n",
    "###### ---> You know that here doing back propagation on all this ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded45e7",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "We use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf632951",
   "metadata": {},
   "source": [
    "##### About matric  : matric in each epoch .--> what tyoe of matric will you use to track the gradient descent .\n",
    "#####  Accuracy  is the metric that we use to kind of track the training process ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=val_ds,\n",
    "    verbose=1,\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf824f0",
   "metadata": {},
   "source": [
    "##### verbose = one --> so that it just prints lots of ouput and we can see , what's going on \n",
    "###### validation data -->  so this validation used in during the each epoch it can help you track the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dff38",
   "metadata": {},
   "source": [
    "##### Before deploy any model ,\n",
    "###### I want to run a test , I want to figure out how well your model  is performing by trying it out on a test data set. So that its not biased. my model has not seen this data set . This is the first time we are trying it  and it can give us good understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db546f20",
   "metadata": {},
   "source": [
    "### Plotting the Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78527d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8f03a",
   "metadata": {},
   "source": [
    "##### loss, accuracy, val loss etc are a python list containing values of loss, accuracy etc at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11226f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4eb91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['loss'][:5] # show loss for first 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df113b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6130d",
   "metadata": {},
   "source": [
    "## Plt training Vs Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a28d8a",
   "metadata": {},
   "source": [
    "## Run prediction on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_ds.take(1):\n",
    "    \n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"first image to predict\")\n",
    "     #---->  PLTING CONVERTING numpy to image formation\n",
    "    plt.imshow(first_image)  \n",
    "     #  --> its actual label \n",
    "    print(\"actual label:\",class_names[first_label]) \n",
    "     #--> its predictions label\n",
    "    batch_prediction = model.predict(images_batch) # --> In batches \n",
    "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])]) \n",
    "    # np.argmax(batch_prediction[0] --> 3d to index of image   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94495fe",
   "metadata": {},
   "source": [
    "### Write a function for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbb569",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(model, images[i].numpy())\n",
    "        actual_class = class_names[labels[i]]\n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class},\\n Predicted: {predicted_class}.\\n Confidence: {confidence}%\")\n",
    "        \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11bf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96816d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470a0f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b815da4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaffbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf9845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187120c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587a6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
